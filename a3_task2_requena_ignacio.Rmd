---
title: "Assignment 3, Task 2: Agglomerative hierarchical clustering"
author: "I. Requena"
date: "2023-02-28"
output: 
  html_document:
    code_folding: hide
---

Instructions

Use **hierarchical clustering by complete linkage** to create a dendrogram showing multivariate clustering for water chemistry by site. To do this youll want to make a data frame that has a single summary row per site (e.g. based on means from all observations at that site), then calculate the Euclidean distance before performing complete linkage agglomerative hierarchical clustering.



```{r setup, echo=TRUE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, results=FALSE)

library(tidyverse)
library(janitor)
library(palmerpenguins)

### Attach package for cluster analysis

library(NbClust)
library(cluster)
library(factoextra)
library(dendextend)
library(ggdendro)
```

### Load & Wrangle data
```{r}

# 1. Load in data and clean column names
df_streams <- read_csv('data/sbc_lter_registered_stream_chemistry.csv') %>% 
  clean_names() %>% 
  select(-timestamp_local)

#2. Replace -999 values with NA
df_streams$site_code <- as.character(df_streams$site_code)
df_streams[df_streams == -999] <- NA

#3. Replace side codes with names
df_streams[df_streams == 'AB00'] <- 'Arroyo Burro'
df_streams[df_streams == 'AT07'] <- 'Atascadero Creek'
df_streams[df_streams == 'DV01'] <- 'Devereaux Creek'
df_streams[df_streams == 'GV01'] <- 'Gaviota Creek'
df_streams[df_streams == 'HO00'] <- 'Arroyo Hondo'
df_streams[df_streams == 'MC00'] <- 'Mission Creek at Montecito'
df_streams[df_streams == 'MC06'] <- 'Mission Creek at Rocky Nook'
df_streams[df_streams == 'ON02'] <- 'Sab Onofre Creek'
df_streams[df_streams == 'RG01'] <- 'Refugio Creek'
df_streams[df_streams == 'RS02'] <- 'Rattlesnake Creek'
df_streams[df_streams == 'SP02'] <- 'San Pedro Creek'
df_streams[df_streams == 'OO02'] <- 'Tecolote Creek'

# 4. View summary to identify which variables have too many NAs (e.g. more than 50%)
summary(df_streams)

# 5. Drop tpc_u_m, tpn_u_m, tpp_u_m, and tss_mgper_liter
df_streams2 <- df_streams %>% 
  select(-tpc_u_m, -tpn_u_m, -tpp_u_m, -tss_mgper_liter)
```

### Introduction:



### Create a complete, scaled version of the data
```{r}
## we know we have three species. But oftentimes we dont know what we have. Now we will see how good it is at picking up clusters by machine learning.

# By complete is that our data with NA will be dropped (in this case we have 11 rows in our penguins data)

streams_complete <- df_streams2 %>% 
  drop_na(tdn_u_m, tdp_u_m)

streams_scale <- streams_complete %>% 
  select(2:7) %>% 
  scale()

rownames(streams_scale) <- streams_complete$site_code


# compare scaled to original vars
# summary(df_streams)
# summary(streams_complete)
# summary(streams_scale)

```


### Estimate number of clusters
```{r}
# number_est <- NbClust(streams_scale, min.nc = 2, max.nc = 10, method = 'kmeans') # min and max number of clusters
# 
# number_est
# 
# fviz_nbclust(streams_scaled, FUNcluster = kmeans, method = 'wss', k.max = 10)
```


# Part 2. Cluster analysis: hierarchical clustering

### Start with complete linkage
```{r}

### Create distance matrix
streams_dist <- dist(streams_scale, method = 'euclidean') # will check distance between all observations (58311 observations)

### Hierarchical clustering (complete linkage)
streams_hc_complete <- hclust(streams_dist, method = 'complete')
### also: single, average, ward.D

### plot a dendrogram
plot(streams_hc_complete, cex= .6, hang = -1)

### cut the tree into three clusters
streams_cut_hc <- cutree(streams_hc_complete, 3)
table(streams_cut_hc, streams_complete$site_code)
```


## 
THe difference between BLR you try to predict unknown data based on known data. What we did today predicts data using unknown data. 



### PART 2

#### Find the Euclidean distances

Use the `stats::dist()` function to find the Euclidean distance in multivariate space between the different observations (countries):

Note: so like you saw in lecture, you *could* manually create the dendrogram using those distances! But it would take a pretty long time, so instead...

#### Perform hierarchical clustering by complete linkage with `stats::hclust()`

The `stats::hclust()` function performs hierarchical clustering, given a dissimilarity matrix (our matrix of euclidean distances), using a linkage that you specify. 

Here, let's use complete linkage (recall from lecture: clusters are merged by the smallest *maximum* distance between two observations in distinct clusters).

```{r}

# Hierarchical clustering (complete linkage)
hc_complete <- hclust(streams_dist, method = "complete" )

# Plot it (base plot):
plot(hc_complete, cex = 0.6, hang = -1)

```

### Now let's do hierarchichal clustering by single linkage & compare

Let's update the linkage to single linkage (recall from lecture: this means that clusters are merged by the *smallest* distance between observations in separate clusters):

```{r}

# Hierarchical clustering (single linkage)
hc_single <- hclust(streams_dist, method = "single" )

# Plot it (base plot):
plot(hc_single, cex = 0.6, hang = -1)

```

We see that it is a bit different when we change the linkage! But how different? 

#### Make a tanglegram to compare dendrograms 

Let's make a **tanglegram** to compare clustering by complete and single linkage! We'll use the `dendextend::tanglegram()` function to make it. 

First, we'll convert to class `dendrogram`, then combine them into a list:

```{r}
# Convert to class dendrogram CONVERTS A STOCK DENDRO TO A FANCY ONE
dend_complete <- as.dendrogram(hc_complete)
dend_simple <- as.dendrogram(hc_single)
```

Cool, now make a tanglegram: 

```{r}
# Make a tanglegram
tanglegram(dend_complete, dend_simple)

# The lines that go across means that the groups (i.e. Korea and Japan) are matched together on both graphics. 

# solid lines are similar linkages. Dotted lines are significant diffs between dendograms


# LETS CLEAN IT UP!
```

That allows us to compare how things are clustered by the different linkages!

Untangling: CLEAN IT UP. Rearanges branches to see a cleaner look

```{r}
entanglement(dend_complete, dend_simple) # lower is better
#> [1] 0.3959222

untangle(dend_complete, dend_simple, method = "step1side") %>% 
  entanglement()
# [1] 0.06415907

# Notice that just because we can get two trees to have horizontal connecting lines, it doesnâ€™t mean these trees are identical (or even very similar topologically):

untangle(dend_complete, dend_simple, method = "step1side") %>% 
   tanglegram(common_subtrees_color_branches = TRUE)


# This is good to decide between the complete vs single linkages
```

#### Want to plot your dendrogram with ggplot instead? Me too. 

Here's how you can make your dendrogram with `ggplot` (here, I'll use the complete linkage example stored as `hc_complete`) using `ggdendrogram()`, a `ggplot` wrapper: 

```{r}
ggdendrogram(hc_complete, 
             rotate = TRUE) + # rotates sideways instead of being vertical
  theme_minimal() +
  labs(x = "Country")

# COOL. Then you can customize w/ usual ggplot tools. 
```

## End Week 6 lab


