---
title: "Assignment 3, Task 2: Agglomerative hierarchical clustering"
author: "I. Requena"
date: "2023-02-28"
output: 
  html_document:
    code_folding: hide
---

Instructions

Use **hierarchical clustering by complete linkage** to create a dendrogram showing multivariate clustering for water chemistry by site. To do this youll want to make a data frame that has a single summary row per site (e.g. based on means from all observations at that site), then calculate the Euclidean distance before performing complete linkage agglomerative hierarchical clustering.



```{r setup, echo=TRUE, message = FALSE, warning = FALSE}
knitr::opts_chunk$set(echo = TRUE, message = FALSE, warning = FALSE, results=FALSE)

library(tidyverse)
library(janitor)
library(palmerpenguins)

### Attach package for cluster analysis

library(NbClust)
library(cluster)
library(factoextra)
library(dendextend)
library(ggdendro)
```

### Load & Wrangle data
```{r}

# 1. Load in data and clean names
df_streams <- read_csv('data/sbc_lter_registered_stream_chemistry.csv') %>% 
  clean_names() %>% 
  select(-timestamp_local)

#2. Replace -999 values with NA
df_streams$site_code <- as.character(df_streams$site_code)
df_streams[df_streams == -999] <- NA

df_streams[df_streams == 'AB00'] <- 'Arroyo Burro'
df_streams[df_streams == 'AT07'] <- 'Atascadero Creek'
df_streams[df_streams == 'DV01'] <- 'Devereaux Creek'
df_streams[df_streams == 'GV01'] <- 'Gaviota Creek'
df_streams[df_streams == 'HO00'] <- 'Arroyo Hondo'
df_streams[df_streams == 'MC00'] <- 'Mission Creek at Montecito'
df_streams[df_streams == 'MC06'] <- 'Mission Creek at Rocky Nook'
df_streams[df_streams == 'ON02'] <- 'Sab Onofre Creek'
df_streams[df_streams == 'RG01'] <- 'Refugio Creek'
df_streams[df_streams == 'RS02'] <- 'Rattlesnake Creek'
df_streams[df_streams == 'SP02'] <- 'San Pedro Creek'
df_streams[df_streams == 'OO02'] <- 'Tecolote Creek'

summary(df_streams)
```

### Introduction:



### Create a complete, scaled version of the data
```{r}
## we know we have three species. But oftentimes we dont know what we have. Now we will see how good it is at picking up clusters by machine learning.

# By complete is that our data with NA will be dropped (in this case we have 11 rows in our penguins data)

streams_complete <- df_streams %>% 
  drop_na() 

rownames(streams_complete) <- df_streams$site_code

streams_scale <- streams_complete %>% 
  scale()



# compare scaled to original vars
# summary(df_streams)
# summary(streams_complete)

```


### Estimate number of clusters
```{r}
number_est <- NbClust(streams_scale, min.nc = 2, max.nc = 10, method = 'kmeans') # min and max number of clusters

number_est

fviz_nbclust(streams_scale, FUNcluster = kmeans, method = 'wss', k.max = 10)
```


# Part 2. Cluster analysis: hierarchical clustering

### Start with complete linkage
```{r}

### Create distance matrix
streams_dist <- dist(streams_scale, method = 'euclidean') # will check distance between all observations (58311 observations)

### Hierarchical clustering (complete linkage)
streams_hc_complete <- hclust(streams_dist, method = 'complete')
### also: single, average, ward.D

### plot a dendrogram
plot(streams_hc_complete, cex= .6, hang = -1)

### cut the tree into three clusters
streams_cut_hc <- cutree(streams_hc_complete, 3)
table(streams_cut_hc, streams_complete$site_code)
```


## 
THe difference between BLR you try to predict unknown data based on known data. What we did today predicts data using unknown data. 



### PART 2


### World Bank Data: read in and simplify
```{r}
wb_env <- read_csv(here::here('data/wb_env.csv'))

# Only keep top 20 greenhouse gas emitters (for simplifying visualization here...)
wb_ghg_20 <- wb_env %>% 
  slice_max(n = 20, ghg)

# summary(wb_ghg_20)

## we can see that the ranges are in super different scales. This will mess it up. If the axis of distance in the thousands, it will not be very good. SOO WE NEED TO RESCALE IT.

# Scale the numeric variables (columns 3:7)
wb_scaled <- wb_ghg_20 %>% 
  select(3:7) %>% 
  scale()
summary(wb_scaled)


rownames(wb_scaled) <- wb_ghg_20$name # take roadnames function and assign country names (it is not a column that will be considered as a variable, its a visual thing). Row #1 will be labeled by country. 
```


#### Find the Euclidean distances

Use the `stats::dist()` function to find the Euclidean distance in multivariate space between the different observations (countries):

```{r}

# Compute dissimilarity values (Euclidean distances):
euc_distance <- dist(wb_scaled, method = "euclidean") ### add diag and upper

# Check out the output:
euc_distance
```


Note: so like you saw in lecture, you *could* manually create the dendrogram using those distances! But it would take a pretty long time, so instead...

#### Perform hierarchical clustering by complete linkage with `stats::hclust()`

The `stats::hclust()` function performs hierarchical clustering, given a dissimilarity matrix (our matrix of euclidean distances), using a linkage that you specify. 

Here, let's use complete linkage (recall from lecture: clusters are merged by the smallest *maximum* distance between two observations in distinct clusters).


```{r}

# Hierarchical clustering (complete linkage)
hc_complete <- hclust(euc_distance, method = "complete" )

# Plot it (base plot):
plot(hc_complete, cex = 0.6, hang = -1)

```

### Now let's do hierarchichal clustering by single linkage & compare

Let's update the linkage to single linkage (recall from lecture: this means that clusters are merged by the *smallest* distance between observations in separate clusters):

```{r}

# Hierarchical clustering (single linkage)
hc_single <- hclust(euc_distance, method = "single" )

# Plot it (base plot):
plot(hc_single, cex = 0.6, hang = -1)

```

We see that it is a bit different when we change the linkage! But how different? 

#### Make a tanglegram to compare dendrograms 

Let's make a **tanglegram** to compare clustering by complete and single linkage! We'll use the `dendextend::tanglegram()` function to make it. 

First, we'll convert to class `dendrogram`, then combine them into a list:

```{r}
# Convert to class dendrogram CONVERTS A STOCK DENDRO TO A FANCY ONE
dend_complete <- as.dendrogram(hc_complete)
dend_simple <- as.dendrogram(hc_single)
```

Cool, now make a tanglegram: 

```{r}
# Make a tanglegram
tanglegram(dend_complete, dend_simple)

# The lines that go across means that the groups (i.e. Korea and Japan) are matched together on both graphics. 

# solid lines are similar linkages. Dotted lines are significant diffs between dendograms


# LETS CLEAN IT UP!
```

That allows us to compare how things are clustered by the different linkages!

Untangling: CLEAN IT UP. Rearanges branches to see a cleaner look

```{r}
entanglement(dend_complete, dend_simple) # lower is better
#> [1] 0.3959222

untangle(dend_complete, dend_simple, method = "step1side") %>% 
  entanglement()
# [1] 0.06415907

# Notice that just because we can get two trees to have horizontal connecting lines, it doesnâ€™t mean these trees are identical (or even very similar topologically):

untangle(dend_complete, dend_simple, method = "step1side") %>% 
   tanglegram(common_subtrees_color_branches = TRUE)


# This is good to decide between the complete vs single linkages
```

#### Want to plot your dendrogram with ggplot instead? Me too. 

Here's how you can make your dendrogram with `ggplot` (here, I'll use the complete linkage example stored as `hc_complete`) using `ggdendrogram()`, a `ggplot` wrapper: 

```{r}
ggdendrogram(hc_complete, 
             rotate = TRUE) + # rotates sideways instead of being vertical
  theme_minimal() +
  labs(x = "Country")

# COOL. Then you can customize w/ usual ggplot tools. 
```

## End Week 6 lab


